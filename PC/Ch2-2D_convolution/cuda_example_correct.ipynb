{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oDfyrVUoi9p0",
        "aO9tJ69Qo7uM",
        "xqxuVMTxpRtq",
        "IXgu6mWGz7Bg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nNS2FA5BR0bU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed390b5-4645-4bd7-ba5d-4c7942132cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize a nvcc plugin for python notebook"
      ],
      "metadata": {
        "id": "n6hCYQF3T2f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "id": "e1MqBxDxUBTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bcc436-965e-4c22-d21f-e2b3fba9d6ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the plugin extension"
      ],
      "metadata": {
        "id": "dlUTHXk-UM0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "id": "V23O5ZJFUQn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43756cc-6206-4e3a-8741-4b24e6f8b95f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp6j96llmq\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 1"
      ],
      "metadata": {
        "id": "CNqvHWAkUi0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define CPU_MATRIX_SIZE 1024\n",
        "\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if( col < n && row < n)\n",
        "    {\n",
        "        int sum = 0;\n",
        "        for(int i = 0; i < n; i++)\n",
        "        {\n",
        "            sum += a[row * n + i] * b[i * n + col];\n",
        "        }\n",
        "        c[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpu_matrix_mult (int *a, int *b, int *c, int n)\n",
        "{\n",
        "    int i,j,k;\n",
        "    for (i = 0; i < n; i++)\n",
        "    {\n",
        "        for (j = 0; j < n; j++)\n",
        "        {\n",
        "            int sum_mult = 0;\n",
        "            for (k = 0; k < n; k++)\n",
        "            {\n",
        "                sum_mult += a[i*n+k] * b[k*n+j];\n",
        "            }\n",
        "            c[i*n+j] = sum_mult;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrieve some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        a = (int*)malloc(sizeof(int)*CPU_MATRIX_SIZE*CPU_MATRIX_SIZE);\n",
        "        b = (int*)malloc(sizeof(int)*CPU_MATRIX_SIZE*CPU_MATRIX_SIZE);\n",
        "        c = (int*)malloc(sizeof(int)*CPU_MATRIX_SIZE*CPU_MATRIX_SIZE);\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < CPU_MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < CPU_MATRIX_SIZE; ++j) {\n",
        "                a[i * CPU_MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < CPU_MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < CPU_MATRIX_SIZE; ++j) {\n",
        "                b[i * CPU_MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "        // sequential version of matrix multiplication\n",
        "        clock_t begin = clock();\n",
        "        cpu_matrix_mult(a, b, c, CPU_MATRIX_SIZE);\n",
        "        clock_t end = clock();\n",
        "        double time_spent = ((double)((end - begin)) * 1000) / CLOCKS_PER_SEC;\n",
        "        printf(\"Time elapsed on naive CPU sequential matrix multiplication of %dx%d . %dx%d: %f ms\\n\\n\", CPU_MATRIX_SIZE, CPU_MATRIX_SIZE, CPU_MATRIX_SIZE, CPU_MATRIX_SIZE, time_spent);\n",
        "        free(a);\n",
        "        free(b);\n",
        "        free(c);\n",
        "    }\n",
        "\n",
        "    for(block_size= 4; block_size <= 32; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "patSEnDlUqdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0829d134-9746-4bdf-d989-1be4acd5c101"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive CPU sequential matrix multiplication of 1024x1024 . 1024x1024: 8504.407000 ms\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (4): 7429.335938 ms.\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (8): 6484.407227 ms.\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (16): 2355.671143 ms.\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (32): 1736.601562 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 32)"
      ],
      "metadata": {
        "id": "oDfyrVUoi9p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 32\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 32; block_size <= 32; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glD-VIgTjDnb",
        "outputId": "f4566706-e730-460d-f25f-8064cba97ee2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (32): 1447.536133 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 16)"
      ],
      "metadata": {
        "id": "aO9tJ69Qo7uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 16; block_size <= 16; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvHlJU3Yo3kT",
        "outputId": "1a8ffa51-2640-48eb-9bda-39dbda53c9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (16): 1712.394165 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 8)"
      ],
      "metadata": {
        "id": "xqxuVMTxpRtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 8\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 8; block_size <= 8; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c309dndnpVHq",
        "outputId": "d81c331f-8ff1-46a5-aa33-5d922f85ffc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (8): 2694.651123 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 4)"
      ],
      "metadata": {
        "id": "IXgu6mWGz7Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 4\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 4; block_size <= 4; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aaFsMqM0GWw",
        "outputId": "12195038-c047-4065-c725-d7c145393ff1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (4): 8289.276367 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}