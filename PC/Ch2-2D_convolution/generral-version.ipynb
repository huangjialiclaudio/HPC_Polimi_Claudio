{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "nNS2FA5BR0bU",
        "outputId": "a1051789-044d-4993-8c45-de04893d6181",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T12:58:17.002485Z",
          "iopub.execute_input": "2024-12-10T12:58:17.002749Z",
          "iopub.status.idle": "2024-12-10T12:58:18.05082Z",
          "shell.execute_reply.started": "2024-12-10T12:58:17.002721Z",
          "shell.execute_reply": "2024-12-10T12:58:18.049931Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize a nvcc plugin for python notebook"
      ],
      "metadata": {
        "id": "n6hCYQF3T2f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "id": "e1MqBxDxUBTo",
        "outputId": "ec152560-0e2a-403c-f919-04f023b34a9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T12:58:24.427948Z",
          "iopub.execute_input": "2024-12-10T12:58:24.428757Z",
          "iopub.status.idle": "2024-12-10T12:58:33.852564Z",
          "shell.execute_reply.started": "2024-12-10T12:58:24.428722Z",
          "shell.execute_reply": "2024-12-10T12:58:33.851446Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the plugin extension"
      ],
      "metadata": {
        "id": "dlUTHXk-UM0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "id": "V23O5ZJFUQn4",
        "outputId": "a30cc0cf-35e1-4c5e-e49e-dade1a43c842",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T12:58:39.724624Z",
          "iopub.execute_input": "2024-12-10T12:58:39.725287Z",
          "iopub.status.idle": "2024-12-10T13:00:06.787313Z",
          "shell.execute_reply.started": "2024-12-10T12:58:39.725247Z",
          "shell.execute_reply": "2024-12-10T13:00:06.786445Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpktvosvsg\".\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve some info about the CUDA device"
      ],
      "metadata": {
        "id": "7TW_Pb-DV_U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    // retrieve some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "LruOdByVVl16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8186f3c2-cb01-4a63-ef9a-71c9f5fe1ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tile = 32"
      ],
      "metadata": {
        "id": "PoxMX1DfAyZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define MASK_SIZE 5\n",
        "#define FILTER_RADIUS (MASK_SIZE / 2)\n",
        "\n",
        "// tile size\n",
        "#define IN_TILE_DIM 32\n",
        "#define OUT_TILE_DIM (IN_TILE_DIM - 2 * FILTER_RADIUS)\n",
        "\n",
        "__constant__ float dc_F[(2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1)];\n",
        "\n",
        "\n",
        "// Performing 2D convolution on the CPU to verify the correctness of the GPU results.\n",
        "void host_convolution_2d(float *N, float *F, float *P, int width, int height, int r)\n",
        "{\n",
        "    int filter_dim = 2 * r + 1;\n",
        "    for (int row = 0; row < height; row++)\n",
        "    {\n",
        "        for (int col = 0; col < width; col++)\n",
        "        {\n",
        "            float p_value = 0.0f;\n",
        "            for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "                {\n",
        "                    int n_row = row - r + f_row;\n",
        "                    int n_col = col - r + f_col;\n",
        "                    if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                    {\n",
        "                        p_value += N[n_row * width + n_col] * F[f_row * filter_dim + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Verify the difference between the GPU convolution result and the CPU result.\n",
        "void verify_convolution_result(float *N, float *F, float *P_gpu, int width, int height, int r, float threshold = 1e0f)\n",
        "{\n",
        "    // Allocate CPU output array\n",
        "    float *P_cpu = (float *)malloc(width * height * sizeof(float));\n",
        "\n",
        "    // Using CPU to perform convolution\n",
        "    host_convolution_2d(N, F, P_cpu, width, height, r);\n",
        "\n",
        "    // Calculation error\n",
        "    double max_error = 0.0;\n",
        "    double sum_error = 0.0;\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        double err = fabs(P_cpu[i] - P_gpu[i]);\n",
        "        if (err > max_error)\n",
        "        {\n",
        "            max_error = err;\n",
        "        }\n",
        "        sum_error += err;\n",
        "    }\n",
        "\n",
        "    double avg_error = sum_error / (width * height);\n",
        "\n",
        "    printf(\"Verification Results:\\n\");\n",
        "    printf(\"Max error: %e\\n\", max_error);\n",
        "    printf(\"Average error: %e\\n\", avg_error);\n",
        "\n",
        "    if (max_error < threshold)\n",
        "    {\n",
        "        printf(\"Result is correct within the threshold.\\n\");\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Result differs more than the threshold!\\n\");\n",
        "    }\n",
        "\n",
        "    // Release memory\n",
        "    free(P_cpu);\n",
        "}\n",
        "\n",
        "\n",
        "// basic 2d convolution, each thread compute the each element of the output tensor\n",
        "__global__ void convolution_2d_basic_kernel(float *N, float *F, float *P, int r, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    F: filter tensor\n",
        "    P: output tensor\n",
        "    r: filter radius (2r+1)x(2r+1)\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    */\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        float p_value = 0.0;\n",
        "        for (int f_row = 0; f_row < 2 * r + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * r + 1; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * F[f_row * (2 * r + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// constatn memory version of 2d convolution, each thread compute the each element of the output tensor\n",
        "__global__ void convolution_2d_constant_mem_kernel(float *N, float *P, int r, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    r: filter radius (2r+1)x(2r+1)\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        float p_value = 0.0;\n",
        "        for (int f_row = 0; f_row < 2 * r + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * r + 1; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * dc_F[f_row * (2 * r + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// tiled version of 2d convolution, a block of threads compute a tile of the output tensor, use the shared memory to cache the input tensor\n",
        "__global__ void convolution_2d_tiled_const_mem_kernel(float *N, float *P, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    __shared__ float s_N[IN_TILE_DIM][IN_TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;\n",
        "    int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    int tile_col = threadIdx.x - FILTER_RADIUS;\n",
        "    int tile_row = threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        if (tile_col >= 0 && tile_col < OUT_TILE_DIM && tile_row >= 0 && tile_row < OUT_TILE_DIM)\n",
        "        {\n",
        "            float p_value = 0.0;\n",
        "            for (int f_row = 0; f_row < 2 * FILTER_RADIUS + 1; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < 2 * FILTER_RADIUS + 1; f_col++)\n",
        "                {\n",
        "                    p_value += s_N[tile_row + f_row][tile_col + f_col] * dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#define TILE_DIM 32\n",
        "// tiled version of 2d convolution, a block of threads compute a tile of the output tensor, use the shared memory to cache the input tensor\n",
        "__global__ void convolution_2d_cached_tiled_const_mem_kernel(float *N, float *P,\n",
        "                                                             int width,\n",
        "                                                             int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    __shared__ float s_N[TILE_DIM][TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "    int row = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (col < width && row < height)\n",
        "    {\n",
        "        float p_value = 0.0;\n",
        "\n",
        "        for (int f_row = 0; f_row < 2 * FILTER_RADIUS + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * FILTER_RADIUS + 1; f_col++)\n",
        "            {\n",
        "                if (threadIdx.x - FILTER_RADIUS + f_col >= 0 &&\n",
        "                    threadIdx.x - FILTER_RADIUS + f_col < TILE_DIM &&\n",
        "                    threadIdx.y - FILTER_RADIUS + f_row >= 0 &&\n",
        "                    threadIdx.y - FILTER_RADIUS + f_row < TILE_DIM)\n",
        "                {\n",
        "                    p_value += s_N[threadIdx.y - FILTER_RADIUS + f_row]\n",
        "                                  [threadIdx.x - FILTER_RADIUS + f_col] *\n",
        "                               dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                }\n",
        "                else\n",
        "                { // load from global memory\n",
        "                    if (row - FILTER_RADIUS + f_row >= 0 &&\n",
        "                        row - FILTER_RADIUS + f_row < height &&\n",
        "                        col - FILTER_RADIUS + f_col >= 0 &&\n",
        "                        col - FILTER_RADIUS + f_col < width)\n",
        "                    {\n",
        "                        p_value += N[(row - FILTER_RADIUS + f_row) * width + (col - FILTER_RADIUS + f_col)] *\n",
        "                                   dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void call_basic_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_F, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for filter tensor\n",
        "    cudaMalloc(&d_F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to device memory\n",
        "    cudaMemcpy(d_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configure block and grid sizes\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up kernel execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for benchmarking\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_basic_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_F);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy data to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Configure kernel launch parameters\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x,\n",
        "                   (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_constant_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output data back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print first 10 elements of output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory and destroy CUDA events\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_tiled_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to constant memory\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Block and grid size configuration\n",
        "    dim3 block_size(IN_TILE_DIM, IN_TILE_DIM);\n",
        "    dim3 grid_size((width + OUT_TILE_DIM - 1) / OUT_TILE_DIM,\n",
        "                   (height + OUT_TILE_DIM - 1) / OUT_TILE_DIM);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution to avoid first-time overhead\n",
        "    convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for averaging\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_cached_tiled_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to constant memory\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Configure block and grid size\n",
        "    dim3 block_size(TILE_DIM, TILE_DIM);\n",
        "    dim3 grid_size((width + TILE_DIM - 1) / TILE_DIM, (height + TILE_DIM - 1) / TILE_DIM);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for averaging\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_cached_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    // input tensor\n",
        "    float *N;\n",
        "    // filter tensor\n",
        "    float *F;\n",
        "    // output tensor\n",
        "    float *P;\n",
        "\n",
        "    // size of input tensor\n",
        "    int width = 8192;\n",
        "    int height = 8192;\n",
        "\n",
        "    // allocate memory for input tensor\n",
        "    N = (float *)malloc(width * height * sizeof(float));\n",
        "    // allocate memory for filter tensor\n",
        "    F = (float *)malloc((2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "    // allocate memory for output tensor\n",
        "    P = (float *)malloc(width * height * sizeof(float));\n",
        "\n",
        "    // initialize input tensor\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        N[i] = i * 0.1f;\n",
        "    }\n",
        "\n",
        "    // initialize filter tensor\n",
        "    for (int i = 0; i < (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1); i++)\n",
        "    {\n",
        "        F[i] = i * 0.05f;\n",
        "    }\n",
        "\n",
        "    // call the basic kernel\n",
        "    call_basic_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the kernel with constant memory\n",
        "    call_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the tiled kernel\n",
        "    call_2d_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the cached tiled kernel\n",
        "    call_2d_cached_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // free memory\n",
        "    free(N);\n",
        "    free(F);\n",
        "    free(P);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "vfHv2_VUCBXH",
        "outputId": "16de15e6-558e-4d29-cd8f-b5899df9c73d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T14:38:10.891902Z",
          "iopub.execute_input": "2024-12-10T14:38:10.892271Z",
          "iopub.status.idle": "2024-12-10T14:38:12.559327Z",
          "shell.execute_reply.started": "2024-12-10T14:38:10.892239Z",
          "shell.execute_reply": "2024-12-10T14:38:12.558435Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time per convolution_2d_basic_kernel: 12.710 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_constant_mem_kernel: 11.244 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_tiled_const_mem_kernel: 9.489 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_cached_tiled_const_mem_kernel: 15.963 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result"
      ],
      "metadata": {
        "id": "89vzTUmRYQN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tile = 16"
      ],
      "metadata": {
        "id": "B8rvawRvAyZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define MASK_SIZE 5\n",
        "#define FILTER_RADIUS (MASK_SIZE / 2)\n",
        "\n",
        "// tile size\n",
        "#define IN_TILE_DIM 16\n",
        "#define OUT_TILE_DIM (IN_TILE_DIM - 2 * FILTER_RADIUS)\n",
        "\n",
        "__constant__ float dc_F[(2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1)];\n",
        "\n",
        "// Performing 2D convolution on the CPU to verify the correctness of the GPU results.\n",
        "void host_convolution_2d(float *N, float *F, float *P, int width, int height, int r)\n",
        "{\n",
        "    int filter_dim = 2 * r + 1;\n",
        "    for (int row = 0; row < height; row++)\n",
        "    {\n",
        "        for (int col = 0; col < width; col++)\n",
        "        {\n",
        "            float p_value = 0.0f;\n",
        "            for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "                {\n",
        "                    int n_row = row - r + f_row;\n",
        "                    int n_col = col - r + f_col;\n",
        "                    if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                    {\n",
        "                        p_value += N[n_row * width + n_col] * F[f_row * filter_dim + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Verify the difference between the GPU convolution result and the CPU result.\n",
        "void verify_convolution_result(float *N, float *F, float *P_gpu, int width, int height, int r, float threshold = 1e0f)\n",
        "{\n",
        "    // Allocate CPU output array\n",
        "    float *P_cpu = (float *)malloc(width * height * sizeof(float));\n",
        "\n",
        "    // Using CPU to perform convolution\n",
        "    host_convolution_2d(N, F, P_cpu, width, height, r);\n",
        "\n",
        "    // Calculation error\n",
        "    double max_error = 0.0;\n",
        "    double sum_error = 0.0;\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        double err = fabs(P_cpu[i] - P_gpu[i]);\n",
        "        if (err > max_error)\n",
        "        {\n",
        "            max_error = err;\n",
        "        }\n",
        "        sum_error += err;\n",
        "    }\n",
        "\n",
        "    double avg_error = sum_error / (width * height);\n",
        "\n",
        "    printf(\"Verification Results:\\n\");\n",
        "    printf(\"Max error: %e\\n\", max_error);\n",
        "    printf(\"Average error: %e\\n\", avg_error);\n",
        "\n",
        "    if (max_error < threshold)\n",
        "    {\n",
        "        printf(\"Result is correct within the threshold.\\n\");\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Result differs more than the threshold!\\n\");\n",
        "    }\n",
        "\n",
        "    // Release memory\n",
        "    free(P_cpu);\n",
        "}\n",
        "\n",
        "// basic 2d convolution, each thread compute the each element of the output tensor\n",
        "__global__ void convolution_2d_basic_kernel(float *N, float *F, float *P, int r, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    F: filter tensor\n",
        "    P: output tensor\n",
        "    r: filter radius (2r+1)x(2r+1)\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    */\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        float p_value = 0.0;\n",
        "        for (int f_row = 0; f_row < 2 * r + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * r + 1; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * F[f_row * (2 * r + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// constatn memory version of 2d convolution, each thread compute the each element of the output tensor\n",
        "__global__ void convolution_2d_constant_mem_kernel(float *N, float *P, int r, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    r: filter radius (2r+1)x(2r+1)\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        float p_value = 0.0;\n",
        "        for (int f_row = 0; f_row < 2 * r + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * r + 1; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * dc_F[f_row * (2 * r + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// tiled version of 2d convolution, a block of threads compute a tile of the output tensor, use the shared memory to cache the input tensor\n",
        "__global__ void convolution_2d_tiled_const_mem_kernel(float *N, float *P, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    __shared__ float s_N[IN_TILE_DIM][IN_TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;\n",
        "    int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    int tile_col = threadIdx.x - FILTER_RADIUS;\n",
        "    int tile_row = threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        if (tile_col >= 0 && tile_col < OUT_TILE_DIM && tile_row >= 0 && tile_row < OUT_TILE_DIM)\n",
        "        {\n",
        "            float p_value = 0.0;\n",
        "            for (int f_row = 0; f_row < 2 * FILTER_RADIUS + 1; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < 2 * FILTER_RADIUS + 1; f_col++)\n",
        "                {\n",
        "                    p_value += s_N[tile_row + f_row][tile_col + f_col] * dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#define TILE_DIM 16\n",
        "// tiled version of 2d convolution, a block of threads compute a tile of the output tensor, use the shared memory to cache the input tensor\n",
        "__global__ void convolution_2d_cached_tiled_const_mem_kernel(float *N, float *P,\n",
        "                                                             int width,\n",
        "                                                             int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    __shared__ float s_N[TILE_DIM][TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "    int row = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (col < width && row < height)\n",
        "    {\n",
        "        float p_value = 0.0;\n",
        "\n",
        "        for (int f_row = 0; f_row < 2 * FILTER_RADIUS + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * FILTER_RADIUS + 1; f_col++)\n",
        "            {\n",
        "                if (threadIdx.x - FILTER_RADIUS + f_col >= 0 &&\n",
        "                    threadIdx.x - FILTER_RADIUS + f_col < TILE_DIM &&\n",
        "                    threadIdx.y - FILTER_RADIUS + f_row >= 0 &&\n",
        "                    threadIdx.y - FILTER_RADIUS + f_row < TILE_DIM)\n",
        "                {\n",
        "                    p_value += s_N[threadIdx.y - FILTER_RADIUS + f_row]\n",
        "                                  [threadIdx.x - FILTER_RADIUS + f_col] *\n",
        "                               dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                }\n",
        "                else\n",
        "                { // load from global memory\n",
        "                    if (row - FILTER_RADIUS + f_row >= 0 &&\n",
        "                        row - FILTER_RADIUS + f_row < height &&\n",
        "                        col - FILTER_RADIUS + f_col >= 0 &&\n",
        "                        col - FILTER_RADIUS + f_col < width)\n",
        "                    {\n",
        "                        p_value += N[(row - FILTER_RADIUS + f_row) * width + (col - FILTER_RADIUS + f_col)] *\n",
        "                                   dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void call_basic_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_F, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for filter tensor\n",
        "    cudaMalloc(&d_F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to device memory\n",
        "    cudaMemcpy(d_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configure block and grid sizes\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up kernel execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for benchmarking\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_basic_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_F);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy data to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Configure kernel launch parameters\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x,\n",
        "                   (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_constant_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output data back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print first 10 elements of output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory and destroy CUDA events\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_tiled_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to constant memory\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Block and grid size configuration\n",
        "    dim3 block_size(IN_TILE_DIM, IN_TILE_DIM);\n",
        "    dim3 grid_size((width + OUT_TILE_DIM - 1) / OUT_TILE_DIM,\n",
        "                   (height + OUT_TILE_DIM - 1) / OUT_TILE_DIM);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution to avoid first-time overhead\n",
        "    convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for averaging\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_cached_tiled_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to constant memory\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Configure block and grid size\n",
        "    dim3 block_size(TILE_DIM, TILE_DIM);\n",
        "    dim3 grid_size((width + TILE_DIM - 1) / TILE_DIM, (height + TILE_DIM - 1) / TILE_DIM);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for averaging\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_cached_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    // input tensor\n",
        "    float *N;\n",
        "    // filter tensor\n",
        "    float *F;\n",
        "    // output tensor\n",
        "    float *P;\n",
        "\n",
        "    // size of input tensor\n",
        "    int width = 8192;\n",
        "    int height = 8192;\n",
        "\n",
        "    // allocate memory for input tensor\n",
        "    N = (float *)malloc(width * height * sizeof(float));\n",
        "    // allocate memory for filter tensor\n",
        "    F = (float *)malloc((2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "    // allocate memory for output tensor\n",
        "    P = (float *)malloc(width * height * sizeof(float));\n",
        "\n",
        "    // initialize input tensor\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        N[i] = i * 0.1f;\n",
        "    }\n",
        "\n",
        "    // initialize filter tensor\n",
        "    for (int i = 0; i < (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1); i++)\n",
        "    {\n",
        "        F[i] = i * 0.05f;\n",
        "    }\n",
        "\n",
        "    // call the basic kernel\n",
        "    call_basic_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the kernel with constant memory\n",
        "    call_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the tiled kernel\n",
        "    call_2d_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the cached tiled kernel\n",
        "    call_2d_cached_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // free memory\n",
        "    free(N);\n",
        "    free(F);\n",
        "    free(P);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ctsef02Z2aYI",
        "execution": {
          "iopub.status.busy": "2024-12-10T14:07:15.442065Z",
          "iopub.execute_input": "2024-12-10T14:07:15.442612Z",
          "iopub.status.idle": "2024-12-10T14:07:17.177365Z",
          "shell.execute_reply.started": "2024-12-10T14:07:15.44258Z",
          "shell.execute_reply": "2024-12-10T14:07:17.176439Z"
        },
        "outputId": "d6f4e8e9-b932-41a9-d91d-38b5064c05fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time per convolution_2d_basic_kernel: 13.989 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_constant_mem_kernel: 12.427 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_tiled_const_mem_kernel: 8.521 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_cached_tiled_const_mem_kernel: 16.733 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result"
      ],
      "metadata": {
        "id": "hucq-qCQYi2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tile = 8"
      ],
      "metadata": {
        "id": "tLHRFGNqAyZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define MASK_SIZE 5\n",
        "#define FILTER_RADIUS (MASK_SIZE / 2)\n",
        "\n",
        "// tile size\n",
        "#define IN_TILE_DIM 8\n",
        "#define OUT_TILE_DIM (IN_TILE_DIM - 2 * FILTER_RADIUS)\n",
        "\n",
        "__constant__ float dc_F[(2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1)];\n",
        "\n",
        "// Performing 2D convolution on the CPU to verify the correctness of the GPU results.\n",
        "void host_convolution_2d(float *N, float *F, float *P, int width, int height, int r)\n",
        "{\n",
        "    int filter_dim = 2 * r + 1;\n",
        "    for (int row = 0; row < height; row++)\n",
        "    {\n",
        "        for (int col = 0; col < width; col++)\n",
        "        {\n",
        "            float p_value = 0.0f;\n",
        "            for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "                {\n",
        "                    int n_row = row - r + f_row;\n",
        "                    int n_col = col - r + f_col;\n",
        "                    if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                    {\n",
        "                        p_value += N[n_row * width + n_col] * F[f_row * filter_dim + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Verify the difference between the GPU convolution result and the CPU result.\n",
        "void verify_convolution_result(float *N, float *F, float *P_gpu, int width, int height, int r, float threshold = 1e0f)\n",
        "{\n",
        "    // Allocate CPU output array\n",
        "    float *P_cpu = (float *)malloc(width * height * sizeof(float));\n",
        "\n",
        "    // Using CPU to perform convolution\n",
        "    host_convolution_2d(N, F, P_cpu, width, height, r);\n",
        "\n",
        "    // Calculation error\n",
        "    double max_error = 0.0;\n",
        "    double sum_error = 0.0;\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        double err = fabs(P_cpu[i] - P_gpu[i]);\n",
        "        if (err > max_error)\n",
        "        {\n",
        "            max_error = err;\n",
        "        }\n",
        "        sum_error += err;\n",
        "    }\n",
        "\n",
        "    double avg_error = sum_error / (width * height);\n",
        "\n",
        "    printf(\"Verification Results:\\n\");\n",
        "    printf(\"Max error: %e\\n\", max_error);\n",
        "    printf(\"Average error: %e\\n\", avg_error);\n",
        "\n",
        "    if (max_error < threshold)\n",
        "    {\n",
        "        printf(\"Result is correct within the threshold.\\n\");\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Result differs more than the threshold!\\n\");\n",
        "    }\n",
        "\n",
        "    // Release memory\n",
        "    free(P_cpu);\n",
        "}\n",
        "\n",
        "// basic 2d convolution, each thread compute the each element of the output tensor\n",
        "__global__ void convolution_2d_basic_kernel(float *N, float *F, float *P, int r, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    F: filter tensor\n",
        "    P: output tensor\n",
        "    r: filter radius (2r+1)x(2r+1)\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    */\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        float p_value = 0.0;\n",
        "        for (int f_row = 0; f_row < 2 * r + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * r + 1; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * F[f_row * (2 * r + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// constatn memory version of 2d convolution, each thread compute the each element of the output tensor\n",
        "__global__ void convolution_2d_constant_mem_kernel(float *N, float *P, int r, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    r: filter radius (2r+1)x(2r+1)\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        float p_value = 0.0;\n",
        "        for (int f_row = 0; f_row < 2 * r + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * r + 1; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * dc_F[f_row * (2 * r + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// tiled version of 2d convolution, a block of threads compute a tile of the output tensor, use the shared memory to cache the input tensor\n",
        "__global__ void convolution_2d_tiled_const_mem_kernel(float *N, float *P, int width, int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    __shared__ float s_N[IN_TILE_DIM][IN_TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;\n",
        "    int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    int tile_col = threadIdx.x - FILTER_RADIUS;\n",
        "    int tile_row = threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        if (tile_col >= 0 && tile_col < OUT_TILE_DIM && tile_row >= 0 && tile_row < OUT_TILE_DIM)\n",
        "        {\n",
        "            float p_value = 0.0;\n",
        "            for (int f_row = 0; f_row < 2 * FILTER_RADIUS + 1; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < 2 * FILTER_RADIUS + 1; f_col++)\n",
        "                {\n",
        "                    p_value += s_N[tile_row + f_row][tile_col + f_col] * dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#define TILE_DIM 8\n",
        "// tiled version of 2d convolution, a block of threads compute a tile of the output tensor, use the shared memory to cache the input tensor\n",
        "__global__ void convolution_2d_cached_tiled_const_mem_kernel(float *N, float *P,\n",
        "                                                             int width,\n",
        "                                                             int height)\n",
        "{\n",
        "    /*\n",
        "    N: input tensor\n",
        "    P: output tensor\n",
        "    width: width of input tensor\n",
        "    height: height of input tensor\n",
        "    N and P has the same size\n",
        "    use constant memory for the filter tensor F\n",
        "    */\n",
        "\n",
        "    __shared__ float s_N[TILE_DIM][TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "    int row = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0.0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (col < width && row < height)\n",
        "    {\n",
        "        float p_value = 0.0;\n",
        "\n",
        "        for (int f_row = 0; f_row < 2 * FILTER_RADIUS + 1; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < 2 * FILTER_RADIUS + 1; f_col++)\n",
        "            {\n",
        "                if (threadIdx.x - FILTER_RADIUS + f_col >= 0 &&\n",
        "                    threadIdx.x - FILTER_RADIUS + f_col < TILE_DIM &&\n",
        "                    threadIdx.y - FILTER_RADIUS + f_row >= 0 &&\n",
        "                    threadIdx.y - FILTER_RADIUS + f_row < TILE_DIM)\n",
        "                {\n",
        "                    p_value += s_N[threadIdx.y - FILTER_RADIUS + f_row]\n",
        "                                  [threadIdx.x - FILTER_RADIUS + f_col] *\n",
        "                               dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                }\n",
        "                else\n",
        "                { // load from global memory\n",
        "                    if (row - FILTER_RADIUS + f_row >= 0 &&\n",
        "                        row - FILTER_RADIUS + f_row < height &&\n",
        "                        col - FILTER_RADIUS + f_col >= 0 &&\n",
        "                        col - FILTER_RADIUS + f_col < width)\n",
        "                    {\n",
        "                        p_value += N[(row - FILTER_RADIUS + f_row) * width + (col - FILTER_RADIUS + f_col)] *\n",
        "                                   dc_F[f_row * (2 * FILTER_RADIUS + 1) + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void call_basic_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_F, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for filter tensor\n",
        "    cudaMalloc(&d_F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to device memory\n",
        "    cudaMemcpy(d_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configure block and grid sizes\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up kernel execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for benchmarking\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_basic_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_F);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy data to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Configure kernel launch parameters\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x,\n",
        "                   (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_constant_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output data back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print first 10 elements of output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory and destroy CUDA events\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_tiled_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to constant memory\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Block and grid size configuration\n",
        "    dim3 block_size(IN_TILE_DIM, IN_TILE_DIM);\n",
        "    dim3 grid_size((width + OUT_TILE_DIM - 1) / OUT_TILE_DIM,\n",
        "                   (height + OUT_TILE_DIM - 1) / OUT_TILE_DIM);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution to avoid first-time overhead\n",
        "    convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for averaging\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_cached_tiled_constant_mem_kernel(float *N, float *F, float *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    float *d_N, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(float));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(float));\n",
        "\n",
        "    // Copy input tensor to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    // Copy filter tensor to constant memory\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "\n",
        "    // Configure block and grid size\n",
        "    dim3 block_size(TILE_DIM, TILE_DIM);\n",
        "    dim3 grid_size((width + TILE_DIM - 1) / TILE_DIM, (height + TILE_DIM - 1) / TILE_DIM);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Warm-up execution (optional, avoids first-time overhead)\n",
        "    convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel 10 times for averaging\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    // Print the average time per kernel execution\n",
        "    printf(\"Average time per convolution_2d_cached_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%f, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    // input tensor\n",
        "    float *N;\n",
        "    // filter tensor\n",
        "    float *F;\n",
        "    // output tensor\n",
        "    float *P;\n",
        "\n",
        "    // size of input tensor\n",
        "    int width = 8192;\n",
        "    int height = 8192;\n",
        "\n",
        "    // allocate memory for input tensor\n",
        "    N = (float *)malloc(width * height * sizeof(float));\n",
        "    // allocate memory for filter tensor\n",
        "    F = (float *)malloc((2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(float));\n",
        "    // allocate memory for output tensor\n",
        "    P = (float *)malloc(width * height * sizeof(float));\n",
        "\n",
        "    // initialize input tensor\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        N[i] = i * 0.1f;\n",
        "    }\n",
        "\n",
        "    // initialize filter tensor\n",
        "    for (int i = 0; i < (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1); i++)\n",
        "    {\n",
        "        F[i] = i * 0.05f;\n",
        "    }\n",
        "\n",
        "    // call the basic kernel\n",
        "    call_basic_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the kernel with constant memory\n",
        "    call_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the tiled kernel\n",
        "    call_2d_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // call the cached tiled kernel\n",
        "    call_2d_cached_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    // free memory\n",
        "    free(N);\n",
        "    free(F);\n",
        "    free(P);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T14:08:40.895546Z",
          "iopub.execute_input": "2024-12-10T14:08:40.895883Z",
          "iopub.status.idle": "2024-12-10T14:08:42.613309Z",
          "shell.execute_reply.started": "2024-12-10T14:08:40.895855Z",
          "shell.execute_reply": "2024-12-10T14:08:42.612449Z"
        },
        "id": "Ro11uoaMAyZV",
        "outputId": "2f6707ab-671e-43dc-aca3-21da2995cdb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time per convolution_2d_basic_kernel: 12.987 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_constant_mem_kernel: 11.763 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_tiled_const_mem_kernel: 18.983 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "Average time per convolution_2d_cached_tiled_const_mem_kernel: 19.725 ms\n",
            "Verification Results:\n",
            "Max error: 2.400000e+01\n",
            "Average error: 1.313119e+00\n",
            "Result differs more than the threshold!\n",
            "7865.159668, 10241.650391, 12495.500977, 12496.775391, 12498.050781, 12499.325195, 12500.600586, 12501.875977, 12503.151367, 12504.425781, \n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result"
      ],
      "metadata": {
        "id": "utSKqk5MYxJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integer version"
      ],
      "metadata": {
        "id": "Wcz94GLUY31b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define MASK_SIZE 5\n",
        "#define FILTER_RADIUS (MASK_SIZE / 2)\n",
        "\n",
        "// tile size\n",
        "#define IN_TILE_DIM 32\n",
        "#define OUT_TILE_DIM (IN_TILE_DIM - 2 * FILTER_RADIUS)\n",
        "\n",
        "__constant__ int dc_F[(2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1)];\n",
        "\n",
        "// Performing 2D convolution on the CPU to verify the correctness of the GPU results.\n",
        "void host_convolution_2d(int *N, int *F, int *P, int width, int height, int r)\n",
        "{\n",
        "    int filter_dim = 2 * r + 1;\n",
        "    for (int row = 0; row < height; row++)\n",
        "    {\n",
        "        for (int col = 0; col < width; col++)\n",
        "        {\n",
        "            int p_value = 0;\n",
        "            for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "                {\n",
        "                    int n_row = row - r + f_row;\n",
        "                    int n_col = col - r + f_col;\n",
        "                    if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                    {\n",
        "                        p_value += N[n_row * width + n_col] * F[f_row * filter_dim + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Verify the difference between the GPU convolution result and the CPU result.\n",
        "void verify_convolution_result(int *N, int *F, int *P_gpu, int width, int height, int r, int threshold = 0)\n",
        "{\n",
        "    // Allocate CPU output array\n",
        "    int *P_cpu = (int *)malloc(width * height * sizeof(int));\n",
        "\n",
        "    // Using CPU to perform convolution\n",
        "    host_convolution_2d(N, F, P_cpu, width, height, r);\n",
        "\n",
        "    // Calculation error\n",
        "    int max_error = 0;\n",
        "    long long sum_error = 0;\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        int err = abs(P_cpu[i] - P_gpu[i]);\n",
        "        if (err > max_error)\n",
        "        {\n",
        "            max_error = err;\n",
        "        }\n",
        "        sum_error += err;\n",
        "    }\n",
        "\n",
        "    double avg_error = (double)sum_error / (width * height);\n",
        "\n",
        "    printf(\"Verification Results:\\n\");\n",
        "    printf(\"Max error: %d\\n\", max_error);\n",
        "    printf(\"Average error: %.6f\\n\", avg_error);\n",
        "\n",
        "    if (max_error <= threshold)\n",
        "    {\n",
        "        printf(\"Result is correct within the threshold.\\n\");\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Result differs more than the threshold!\\n\");\n",
        "    }\n",
        "\n",
        "    // Release memory\n",
        "    free(P_cpu);\n",
        "}\n",
        "\n",
        "// basic 2d convolution kernel\n",
        "__global__ void convolution_2d_basic_kernel(int *N, int *F, int *P, int r, int width, int height)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        int p_value = 0;\n",
        "        int filter_dim = 2 * r + 1;\n",
        "        for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * F[f_row * filter_dim + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void convolution_2d_constant_mem_kernel(int *N, int *P, int r, int width, int height)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (col < width && row < height) {\n",
        "        int p_value = 0;\n",
        "        int filter_dim = 2 * r + 1;\n",
        "        for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "            {\n",
        "                int n_row = row - r + f_row;\n",
        "                int n_col = col - r + f_col;\n",
        "                if (n_row >= 0 && n_row < height && n_col >= 0 && n_col < width)\n",
        "                {\n",
        "                    p_value += N[n_row * width + n_col] * dc_F[f_row * filter_dim + f_col];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void convolution_2d_tiled_const_mem_kernel(int *N, int *P, int width, int height)\n",
        "{\n",
        "    __shared__ int s_N[IN_TILE_DIM][IN_TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;\n",
        "    int row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    int tile_col = threadIdx.x - FILTER_RADIUS;\n",
        "    int tile_row = threadIdx.y - FILTER_RADIUS;\n",
        "\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        if (tile_col >= 0 && tile_col < OUT_TILE_DIM && tile_row >= 0 && tile_row < OUT_TILE_DIM)\n",
        "        {\n",
        "            int p_value = 0;\n",
        "            int filter_dim = 2 * FILTER_RADIUS + 1;\n",
        "            for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "            {\n",
        "                for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "                {\n",
        "                    p_value += s_N[tile_row + f_row][tile_col + f_col] * dc_F[f_row * filter_dim + f_col];\n",
        "                }\n",
        "            }\n",
        "            P[row * width + col] = p_value;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#define TILE_DIM 8\n",
        "__global__ void convolution_2d_cached_tiled_const_mem_kernel(int *N, int *P, int width, int height)\n",
        "{\n",
        "    __shared__ int s_N[TILE_DIM][TILE_DIM];\n",
        "\n",
        "    int col = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "    int row = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "    if (col >= 0 && col < width && row >= 0 && row < height)\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        s_N[threadIdx.y][threadIdx.x] = 0;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (col < width && row < height)\n",
        "    {\n",
        "        int p_value = 0;\n",
        "        int filter_dim = 2 * FILTER_RADIUS + 1;\n",
        "        for (int f_row = 0; f_row < filter_dim; f_row++)\n",
        "        {\n",
        "            for (int f_col = 0; f_col < filter_dim; f_col++)\n",
        "            {\n",
        "                int s_x = threadIdx.x - FILTER_RADIUS + f_col;\n",
        "                int s_y = threadIdx.y - FILTER_RADIUS + f_row;\n",
        "\n",
        "                if (s_x >= 0 && s_x < TILE_DIM && s_y >= 0 && s_y < TILE_DIM)\n",
        "                {\n",
        "                    p_value += s_N[s_y][s_x] * dc_F[f_row * filter_dim + f_col];\n",
        "                }\n",
        "                else\n",
        "                {\n",
        "                    int g_x = col - FILTER_RADIUS + f_col;\n",
        "                    int g_y = row - FILTER_RADIUS + f_row;\n",
        "                    if (g_y >= 0 && g_y < height && g_x >= 0 && g_x < width)\n",
        "                    {\n",
        "                        p_value += N[g_y * width + g_x] * dc_F[f_row * filter_dim + f_col];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        P[row * width + col] = p_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void call_basic_kernel(int *N, int *F, int *P, int width, int height)\n",
        "{\n",
        "    // Device memory pointers\n",
        "    int *d_N, *d_F, *d_P;\n",
        "\n",
        "    // Allocate device memory for input tensor\n",
        "    cudaMalloc(&d_N, width * height * sizeof(int));\n",
        "    // Allocate device memory for filter tensor\n",
        "    cudaMalloc(&d_F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(int));\n",
        "    // Allocate device memory for output tensor\n",
        "    cudaMalloc(&d_P, width * height * sizeof(int));\n",
        "\n",
        "    // Copy input tensor and filter to device memory\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configure block and grid sizes\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    // Execute the kernel multiple times for benchmarking\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_basic_kernel<<<grid_size, block_size>>>(d_N, d_F, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"Average time per convolution_2d_basic_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    // Copy output tensor back to host memory\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // verification\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    // Print the first 10 elements of the output tensor\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%d, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_F);\n",
        "    cudaFree(d_P);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_constant_mem_kernel(int *N, int *F, int *P, int width, int height)\n",
        "{\n",
        "    int *d_N, *d_P;\n",
        "\n",
        "    cudaMalloc(&d_N, width * height * sizeof(int));\n",
        "    cudaMalloc(&d_P, width * height * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(int));\n",
        "\n",
        "    dim3 block_size(32, 32);\n",
        "    dim3 grid_size((width + block_size.x - 1) / block_size.x,\n",
        "                   (height + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(start, 0);\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_constant_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, FILTER_RADIUS, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"Average time per convolution_2d_constant_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%d, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_tiled_constant_mem_kernel(int *N, int *F, int *P, int width, int height)\n",
        "{\n",
        "    int *d_N, *d_P;\n",
        "\n",
        "    cudaMalloc(&d_N, width * height * sizeof(int));\n",
        "    cudaMalloc(&d_P, width * height * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(int));\n",
        "\n",
        "    dim3 block_size(IN_TILE_DIM, IN_TILE_DIM);\n",
        "    dim3 grid_size((width + OUT_TILE_DIM - 1) / OUT_TILE_DIM,\n",
        "                   (height + OUT_TILE_DIM - 1) / OUT_TILE_DIM);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(start, 0);\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"Average time per convolution_2d_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%d, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void call_2d_cached_tiled_constant_mem_kernel(int *N, int *F, int *P, int width, int height)\n",
        "{\n",
        "    int *d_N, *d_P;\n",
        "\n",
        "    cudaMalloc(&d_N, width * height * sizeof(int));\n",
        "    cudaMalloc(&d_P, width * height * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_N, N, width * height * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpyToSymbol(dc_F, F, (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(int));\n",
        "\n",
        "    dim3 block_size(TILE_DIM, TILE_DIM);\n",
        "    dim3 grid_size((width + TILE_DIM - 1) / TILE_DIM, (height + TILE_DIM - 1) / TILE_DIM);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(start, 0);\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        convolution_2d_cached_tiled_const_mem_kernel<<<grid_size, block_size>>>(d_N, d_P, width, height);\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float elapsed_time;\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"Average time per convolution_2d_cached_tiled_const_mem_kernel: %.3f ms\\n\", elapsed_time / 10);\n",
        "\n",
        "    cudaMemcpy(P, d_P, width * height * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    verify_convolution_result(N, F, P, width, height, FILTER_RADIUS);\n",
        "\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"%d, \", P[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    cudaFree(d_N);\n",
        "    cudaFree(d_P);\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int width = 8192;\n",
        "    int height = 8192;\n",
        "\n",
        "    int *N = (int *)malloc(width * height * sizeof(int));\n",
        "    int *F = (int *)malloc((2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1) * sizeof(int));\n",
        "    int *P = (int *)malloc(width * height * sizeof(int));\n",
        "\n",
        "    for (int i = 0; i < width * height; i++)\n",
        "    {\n",
        "        N[i] = i;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < (2 * FILTER_RADIUS + 1) * (2 * FILTER_RADIUS + 1); i++)\n",
        "    {\n",
        "        F[i] = i;\n",
        "    }\n",
        "\n",
        "    call_basic_kernel(N, F, P, width, height);\n",
        "    call_constant_mem_kernel(N, F, P, width, height);\n",
        "    call_2d_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "    call_2d_cached_tiled_constant_mem_kernel(N, F, P, width, height);\n",
        "\n",
        "    free(N);\n",
        "    free(F);\n",
        "    free(P);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T14:03:11.301642Z",
          "iopub.execute_input": "2024-12-10T14:03:11.301981Z",
          "iopub.status.idle": "2024-12-10T14:03:15.43457Z",
          "shell.execute_reply.started": "2024-12-10T14:03:11.301955Z",
          "shell.execute_reply": "2024-12-10T14:03:15.433697Z"
        },
        "id": "ek70KCBDAyZW",
        "outputId": "92af345d-d6dc-4c12-ef58-c6726b06dd53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time per convolution_2d_basic_kernel: 12.549 ms\n",
            "Verification Results:\n",
            "Max error: 0\n",
            "Average error: 0.000000\n",
            "Result is correct within the threshold.\n",
            "1573032, 2048330, 2499100, 2499355, 2499610, 2499865, 2500120, 2500375, 2500630, 2500885, \n",
            "Average time per convolution_2d_constant_mem_kernel: 10.876 ms\n",
            "Verification Results:\n",
            "Max error: 0\n",
            "Average error: 0.000000\n",
            "Result is correct within the threshold.\n",
            "1573032, 2048330, 2499100, 2499355, 2499610, 2499865, 2500120, 2500375, 2500630, 2500885, \n",
            "Average time per convolution_2d_tiled_const_mem_kernel: 8.806 ms\n",
            "Verification Results:\n",
            "Max error: 0\n",
            "Average error: 0.000000\n",
            "Result is correct within the threshold.\n",
            "1573032, 2048330, 2499100, 2499355, 2499610, 2499865, 2500120, 2500375, 2500630, 2500885, \n",
            "Average time per convolution_2d_cached_tiled_const_mem_kernel: 20.389 ms\n",
            "Verification Results:\n",
            "Max error: 0\n",
            "Average error: 0.000000\n",
            "Result is correct within the threshold.\n",
            "1573032, 2048330, 2499100, 2499355, 2499610, 2499865, 2500120, 2500375, 2500630, 2500885, \n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### result"
      ],
      "metadata": {
        "id": "heNNSOPWZlkg"
      }
    }
  ]
}