{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oDfyrVUoi9p0",
        "aO9tJ69Qo7uM",
        "xqxuVMTxpRtq",
        "IXgu6mWGz7Bg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNS2FA5BR0bU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e83782e-5693-4591-e23b-48db4f227ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize a nvcc plugin for python notebook"
      ],
      "metadata": {
        "id": "n6hCYQF3T2f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "e1MqBxDxUBTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a373724-e174-41d0-a2cb-eef4efeaa514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-z92012nw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-z92012nw\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=70080c73d0676f6530fb3fc56908c34e627a63057d8e8ed1a3dba8e2c0a0fcee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qq6lml76/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the plugin extension"
      ],
      "metadata": {
        "id": "dlUTHXk-UM0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "V23O5ZJFUQn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b435de-717a-4fc1-a314-e322dff6c0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 1"
      ],
      "metadata": {
        "id": "CNqvHWAkUi0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define CPU_MATRIX_SIZE 1024\n",
        "\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if( col < n && row < n)\n",
        "    {\n",
        "        int sum = 0;\n",
        "        for(int i = 0; i < n; i++)\n",
        "        {\n",
        "            sum += a[row * n + i] * b[i * n + col];\n",
        "        }\n",
        "        c[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpu_matrix_mult (int *a, int *b, int *c, int n)\n",
        "{\n",
        "    int i,j,k;\n",
        "    for (i = 0; i < n; i++)\n",
        "    {\n",
        "        for (j = 0; j < n; j++)\n",
        "        {\n",
        "            int sum_mult = 0;\n",
        "            for (k = 0; k < n; k++)\n",
        "            {\n",
        "                sum_mult += a[i*n+k] * b[k*n+j];\n",
        "            }\n",
        "            c[i*n+j] = sum_mult;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrieve some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        a = (int*)malloc(sizeof(int)*CPU_MATRIX_SIZE*CPU_MATRIX_SIZE);\n",
        "        b = (int*)malloc(sizeof(int)*CPU_MATRIX_SIZE*CPU_MATRIX_SIZE);\n",
        "        c = (int*)malloc(sizeof(int)*CPU_MATRIX_SIZE*CPU_MATRIX_SIZE);\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < CPU_MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < CPU_MATRIX_SIZE; ++j) {\n",
        "                a[i * CPU_MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < CPU_MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < CPU_MATRIX_SIZE; ++j) {\n",
        "                b[i * CPU_MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "        // sequential version of matrix multiplication\n",
        "        clock_t begin = clock();\n",
        "        cpu_matrix_mult(a, b, c, CPU_MATRIX_SIZE);\n",
        "        clock_t end = clock();\n",
        "        double time_spent = ((double)((end - begin)) * 1000) / CLOCKS_PER_SEC;\n",
        "        printf(\"Time elapsed on naive CPU sequential matrix multiplication of %dx%d . %dx%d: %f ms\\n\\n\", CPU_MATRIX_SIZE, CPU_MATRIX_SIZE, CPU_MATRIX_SIZE, CPU_MATRIX_SIZE, time_spent);\n",
        "        free(a);\n",
        "        free(b);\n",
        "        free(c);\n",
        "    }\n",
        "\n",
        "    for(block_size= 4; block_size <= 32; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "patSEnDlUqdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4251af6c-8fda-435d-d824-2514221dddcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive CPU sequential matrix multiplication of 1024x1024 . 1024x1024: 7929.036000 ms\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (4): 7408.363281 ms.\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (8): 6688.598145 ms.\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (16): 2410.977295 ms.\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (32): 1838.651367 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 32)"
      ],
      "metadata": {
        "id": "oDfyrVUoi9p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 32\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 32; block_size <= 32; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glD-VIgTjDnb",
        "outputId": "a01a8427-baa3-41b7-c035-da0fd8b1b95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (32): 1412.809082 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 16)"
      ],
      "metadata": {
        "id": "aO9tJ69Qo7uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 16; block_size <= 16; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvHlJU3Yo3kT",
        "outputId": "1a8ffa51-2640-48eb-9bda-39dbda53c9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (16): 1712.394165 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 8)"
      ],
      "metadata": {
        "id": "xqxuVMTxpRtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 8\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 8; block_size <= 8; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c309dndnpVHq",
        "outputId": "d81c331f-8ff1-46a5-aa33-5d922f85ffc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (8): 2694.651123 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Matrix multiplication version 2 (TILE_WIDTH 4)"
      ],
      "metadata": {
        "id": "IXgu6mWGz7Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#define MATRIX_SIZE 8192\n",
        "#define TILE_WIDTH 4\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a,int *b, int *c, int n)\n",
        "{\n",
        "    __shared__ int ds_M[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ int ds_N[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "\n",
        "  int bx = blockIdx.x;  int by = blockIdx.y;\n",
        "  int tx = threadIdx.x; int ty = threadIdx.y;\n",
        "\n",
        "  int Row = by * blockDim.y + ty;\n",
        "  int Col = bx * blockDim.x + tx;\n",
        "  int Pvalue = 0;\n",
        "\n",
        "  // Loop over the M and N tiles required to compute the P element\n",
        "  for (int p = 0; p < (n-1) / TILE_WIDTH + 1; ++p) {\n",
        "    // Collaborative loading of M and N tiles into shared memory\n",
        "    if(Row < n && p * TILE_WIDTH+tx < n) {\n",
        "        ds_M[ty][tx] = a[Row*n + p*TILE_WIDTH+tx];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_M[ty][tx] = 0.0;\n",
        "    }\n",
        "    if (p*TILE_WIDTH+ty < n && Col < n) {\n",
        "        ds_N[ty][tx] = b[(p*TILE_WIDTH+ty)*n + Col];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        ds_N[ty][tx] = 0.0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if(Row < n && Col < n) {\n",
        "        for (int i = 0; i < TILE_WIDTH; ++i)\n",
        "           Pvalue += ds_M[ty][i] * ds_N[i][tx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "  if (Row < n && Col < n)\n",
        "    c[Row*n+Col] = Pvalue;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int block_size;\n",
        "\n",
        "    /// retrive some info about the CUDA device\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "      cudaDeviceProp prop;\n",
        "      cudaGetDeviceProperties(&prop, i);\n",
        "      printf(\"Device Number: %d\\n\", i);\n",
        "      printf(\"  Device name: %s\\n\", prop.name);\n",
        "      printf(\"  max Blocks Per MultiProcessor: %d\\n\", prop.maxBlocksPerMultiProcessor);\n",
        "      printf(\"  max Threads Per MultiProcessor: %d\\n\", prop.maxThreadsPerMultiProcessor);\n",
        "      printf(\"  max Threads Per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "      printf(\"  num SM: %d\\n\", prop.multiProcessorCount);\n",
        "      printf(\"  num bytes sharedMem Per Block: %d\\n\", prop.sharedMemPerBlock);\n",
        "      printf(\"  num bytes sharedMem Per Multiprocessor: %d\\n\", prop.sharedMemPerMultiprocessor);\n",
        "      printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "      printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "      printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "\n",
        "    for(block_size= 4; block_size <= 4; block_size *= 2)\n",
        "    {\n",
        "        int *a, *b, *c;\n",
        "        cudaMallocManaged((void **) &a, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &b, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "        cudaMallocManaged((void **) &c, sizeof(int)*MATRIX_SIZE*MATRIX_SIZE);\n",
        "\n",
        "        // initialize matrix A\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                a[i * MATRIX_SIZE + j] = 2;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // initialize matrix B\n",
        "        for (int i = 0; i < MATRIX_SIZE; ++i) {\n",
        "            for (int j = 0; j < MATRIX_SIZE; ++j) {\n",
        "                b[i * MATRIX_SIZE + j] = 3;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float  naive_gpu_elapsed_time_ms;\n",
        "\n",
        "        // some events to count the execution time\n",
        "        //clock_t st, end;\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        unsigned int grid_rows = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        unsigned int grid_cols = (MATRIX_SIZE + block_size - 1) / block_size;\n",
        "        dim3 dimGrid(grid_cols, grid_rows);\n",
        "        dim3 dimBlock(block_size, block_size);\n",
        "\n",
        "\n",
        "        cudaEventRecord(start, 0);\n",
        "        gpu_matrix_mult<<<dimGrid, dimBlock>>>(a, b, c, MATRIX_SIZE);\n",
        "        cudaThreadSynchronize();\n",
        "\n",
        "        // time counting terminate\n",
        "\n",
        "        cudaEventRecord(stop, 0);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        // compute time elapsed on GPU computing\n",
        "        cudaEventElapsedTime(&naive_gpu_elapsed_time_ms, start, stop);\n",
        "        printf(\"Time elapsed on naive GPU matrix multiplication of %dx%d . %dx%d (%d): %f ms.\\n\\n\", MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, MATRIX_SIZE, block_size, naive_gpu_elapsed_time_ms);\n",
        "\n",
        "\n",
        "        // free memory\n",
        "        cudaFree(a);\n",
        "        cudaFree(b);\n",
        "        cudaFree(c);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aaFsMqM0GWw",
        "outputId": "750dba3f-817a-4909-e62e-99d45a9584d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  max Blocks Per MultiProcessor: 16\n",
            "  max Threads Per MultiProcessor: 1024\n",
            "  max Threads Per Block: 1024\n",
            "  num SM: 40\n",
            "  num bytes sharedMem Per Block: 49152\n",
            "  num bytes sharedMem Per Multiprocessor: 65536\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "Time elapsed on naive GPU matrix multiplication of 8192x8192 . 8192x8192 (4): 8358.279297 ms.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}